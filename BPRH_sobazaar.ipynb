{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import sample\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# define function\n",
    "\n",
    "def adv_index(list_to_index, list_to_match):\n",
    "    return [ind for ind, match in enumerate(list_to_index) if match in list_to_match]\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# generate a small data\n",
    "\n",
    "data = pd.read_csv('data/sb_unique_actions_20.csv')\n",
    "# change column name\n",
    "data.columns = ['ItemID', 'UserID', 'Action', 'Action_Date', 'Action_Time',\n",
    "       'SessionId']\n",
    "data_temp = data[['ItemID', 'UserID', 'Action']]\n",
    "# drop duplicates\n",
    "data_temp.drop_duplicates(inplace=True, ignore_index=True)\n",
    "data = data_temp\n",
    "del data_temp\n",
    "# rename user and item\n",
    "user_original_id_list = sorted(set(data.UserID))\n",
    "item_original_id_list = sorted(set(data.ItemID))\n",
    "\n",
    "data.UserID = data.UserID.apply(lambda x: user_original_id_list.index(x))\n",
    "data.ItemID = data.ItemID.apply(lambda x: item_original_id_list.index(x))\n",
    "\n",
    "item_list = sorted(set(data.ItemID))\n",
    "user_list = sorted(set(data.UserID))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# parameter setting\n",
    "dim = 20\n",
    "num_iter = 5000\n",
    "omega = 100\n",
    "rho = 1\n",
    "lambda_u = 0.1\n",
    "lambda_v = 0.1\n",
    "lambda_b = 0.1\n",
    "gamma = 0.008\n",
    "num_u = len(user_list)\n",
    "num_i = len(item_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4514/4514 [01:26<00:00, 52.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calculate auxiliary-target correlation C for every user and each types of auxiliary action\n",
    "# Here we only have one auxiliary action 'V' for 'View'\n",
    "\n",
    "# TODO: what if a user has no purchase, no auxiliary action, or no no-action\n",
    "\n",
    "target_action = 'P'\n",
    "auxiliary_action = ['V']\n",
    "C_u = dict()\n",
    "user_set_bar = tqdm(user_list)\n",
    "for u in user_set_bar:\n",
    "    C_u[u] = dict()\n",
    "    I_t_u = set(data[(data.UserID == u) & (data.Action == target_action)].ItemID)\n",
    "    # TODO filtered item set\n",
    "    for X in auxiliary_action:\n",
    "        I_a_u = set(data[(data.UserID == u) & (data.Action == X)].ItemID)\n",
    "\n",
    "        C_u_at = len(I_t_u.intersection(I_a_u)) / len(I_t_u) if len(I_t_u) != 0 else 0\n",
    "        C_u_ta = len(I_t_u.intersection(I_a_u)) / len(I_a_u) if len(I_a_u) != 0 else 0\n",
    "\n",
    "        C_u_X = 2 * C_u_at * C_u_ta / (C_u_ta + C_u_at) if C_u_ta + C_u_at != 0 else 1\n",
    "        C_u[u][X] = C_u_X\n",
    "\n",
    "temp = pd.DataFrame.from_dict(C_u, orient='index')\n",
    "# We have only one auxiliary action 'V'\n",
    "temp['alpha'] = omega * rho * temp.V\n",
    "alpha_u = temp\n",
    "del temp\n",
    "alpha_u.reset_index(inplace=True)\n",
    "alpha_u.columns = ['UserID', 'V', 'alpha']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2334/2334 [1:11:50<00:00,  2.19s/it]\n"
     ]
    }
   ],
   "source": [
    "# generate item-set based on co-selection\n",
    "S = dict()\n",
    "item_set_bar = tqdm(item_list)\n",
    "for i in item_set_bar:\n",
    "    S[i] = set()\n",
    "    U_i = set(data[data.ItemID == i].UserID)\n",
    "    for j in item_list:\n",
    "        U_j = set(data[data.ItemID == j].UserID)\n",
    "        if len(U_i.intersection(U_j)) >= 2: S[i].add(j)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# initialization\n",
    "# we include item bias term in the last row of V\n",
    "# and set the last column in U to all-1 vector\n",
    "np.random.seed(20200701)\n",
    "U = np.random.normal(size=(num_u, dim + 1))\n",
    "V = np.random.normal(size=(dim + 1, num_i))\n",
    "U[:, -1] = 1\n",
    "# estimation is U dot V\n",
    "estimation = np.dot(U, V)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ITER 236:   5%|▍         | 237/5000 [00:59<17:14,  4.60it/s, loss=-3.02]C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in exp\n",
      "  import sys\n",
      "ITER 1160:  23%|██▎       | 1161/5000 [05:39<15:45,  4.06it/s, loss=-2.29]"
     ]
    }
   ],
   "source": [
    "# begin iteration\n",
    "with trange(num_iter) as t:\n",
    "    for index in t:\n",
    "        # Description will be displayed on the left\n",
    "        t.set_description('ITER %i' % index)\n",
    "\n",
    "        # Build u, I, J, K\n",
    "        # uniformly sample a user from U\n",
    "        u = sample(set(data.UserID), 1)[0]\n",
    "\n",
    "        # build I\n",
    "        # uniformly sample a item i from I_u_t\n",
    "        I_u_t = set(data[(data.UserID == u) & (data.Action == 'P')].ItemID)\n",
    "        if len(I_u_t) != 0:\n",
    "            i = sample(I_u_t, 1)[0]\n",
    "            # build I = I_u_t cap S_i\n",
    "            I = I_u_t.intersection(S[i])\n",
    "        else: # if no item in I_u_t, then set I to empty set\n",
    "            i = None\n",
    "            I = set()\n",
    "\n",
    "        # build J, since we only have one auxiliary action, we follow the uniform sampling\n",
    "        I_u_oa = set(data[(data.UserID == u) & (data.Action == 'V')].ItemID) - I_u_t# TODO: optimize this\n",
    "        if len(I_u_oa) != 0:\n",
    "            j = sample(I_u_oa, 1)[0]\n",
    "            J = I_u_oa.intersection(S[j])\n",
    "        else: # if no item in I_u_oa, then set J to empty set\n",
    "            j = None\n",
    "            J = set()\n",
    "\n",
    "        # build K\n",
    "        I_u_n = set(data.ItemID) - I_u_t - I_u_oa\n",
    "        if len(I_u_n) != 0:\n",
    "            k = sample(I_u_n, 1)[0]\n",
    "            # build K\n",
    "            K = I_u_n.intersection(S[k])\n",
    "        else: # if no item in I_u_n, then set K to empty set\n",
    "            k = None\n",
    "            K = set()\n",
    "\n",
    "        # calculate intermediate variables\n",
    "        # get specific alpha_u\n",
    "        spec_alpha_u = alpha_u[alpha_u.UserID == u].alpha.values[0]\n",
    "        u_index = user_list.index(u)\n",
    "        U_u = U[u_index, :-1]\n",
    "        # get r_hat_uIJ and r_hat_uJK\n",
    "        r_hat_uI = np.average(estimation[u_index, adv_index(item_list, sorted(I))]) if len(I) != 0 else 0\n",
    "        r_hat_uJ = np.average(estimation[u_index, adv_index(item_list, sorted(J))]) if len(J) != 0 else 0\n",
    "        r_hat_uK = np.average(estimation[u_index, adv_index(item_list, sorted(K))]) if len(K) != 0 else 0\n",
    "\n",
    "        r_hat_uIJ = r_hat_uI - r_hat_uJ\n",
    "        r_hat_uJK = r_hat_uJ - r_hat_uK\n",
    "        # get V_bar_I, V_bar_J, V_bar_K\n",
    "        V_bar_I = np.average(V[:-1, adv_index(item_list, sorted(I))], axis=1) if len(I) != 0 else np.zeros(shape=V[:-1, 0].shape)\n",
    "        V_bar_J = np.average(V[:-1, adv_index(item_list, sorted(J))], axis=1) if len(J) != 0 else np.zeros(shape=V[:-1, 0].shape)\n",
    "        V_bar_K = np.average(V[:-1, adv_index(item_list, sorted(K))], axis=1) if len(K) != 0 else np.zeros(shape=V[:-1, 0].shape)\n",
    "        # get b_I, b_J, b_K\n",
    "        b_I = np.average(V[-1, adv_index(item_list, sorted(I))]) if len(I) != 0 else 0\n",
    "        b_J = np.average(V[-1, adv_index(item_list, sorted(J))]) if len(J) != 0 else 0\n",
    "        b_K = np.average(V[-1, adv_index(item_list, sorted(K))]) if len(K) != 0 else 0\n",
    "\n",
    "        # calculate loss\n",
    "        f_Theta = np.log(sigmoid(r_hat_uIJ / spec_alpha_u)) + np.log(sigmoid(r_hat_uJK))\n",
    "        regula = lambda_u * np.linalg.norm(U_u, ord=2) + lambda_v * ((np.linalg.norm(V_bar_I, ord=2) if len(I) != 0 else 0) + (np.linalg.norm((V_bar_J), ord=2) if len(J) != 0 else 0) + (np.linalg.norm((V_bar_K), ord=2)) if len(K) != 0 else 0) + lambda_b * ((b_I if len(I) != 0 else 0) ** 2 + (b_J if len(J) != 0 else 0) ** 2 + (b_K if len(K) != 0 else 0) ** 2)\n",
    "        bprh_loss = f_Theta - regula\n",
    "\n",
    "        # get derivatives and update\n",
    "\n",
    "        # NABULA U_u\n",
    "        df_dUu = sigmoid(- r_hat_uIJ / spec_alpha_u) / spec_alpha_u * (V_bar_I - V_bar_J) + sigmoid(- r_hat_uJK) * (V_bar_J - V_bar_K)\n",
    "        dR_dUu = 2 * lambda_u * U_u\n",
    "        # update U_u = U_u + gamma * (df_dUu - dR_dUu)\n",
    "        U[u_index, :-1] += gamma * (df_dUu - dR_dUu)\n",
    "\n",
    "        if len(I) != 0:\n",
    "            # NABULA V_i\n",
    "            df_dbi = sigmoid(- r_hat_uIJ / spec_alpha_u) / (len(I) * spec_alpha_u)\n",
    "            dR_dbi = 2 * lambda_b * b_I / len(I)\n",
    "            df_dVi = df_dbi * U_u\n",
    "            dR_dVi = 2 * lambda_v * V_bar_I / len(I)\n",
    "            # update V_i = V_i + gamma * (df_dVi - dR_dVi)\n",
    "            V[:-1, adv_index(item_list, sorted(I))] += gamma * (df_dVi - dR_dVi)[:,None] # trick: transpose here\n",
    "            # update b_i = b_i + gamma * (df_dbi - dR_dbi)\n",
    "            V[-1, adv_index(item_list, sorted(I))] += gamma * (df_dbi - dR_dbi)\n",
    "\n",
    "        if len(J) != 0:\n",
    "            # NABULA V_j\n",
    "            df_dbj = (- sigmoid(- spec_alpha_u * r_hat_uIJ) / spec_alpha_u + sigmoid(- r_hat_uJK)) / len(J)\n",
    "            dR_dbj = 2 * lambda_b * b_J / len(J)\n",
    "            df_dVj = df_dbj * U_u\n",
    "            dR_dVj = 2 * lambda_v * V_bar_J / len(J)\n",
    "            # update V_j = V_j + gamma * (df_dVj - dR_dVj)\n",
    "            V[:-1, adv_index(item_list, sorted(J))] += gamma * (df_dVj - dR_dVj)[:,None] # trick: transpose here\n",
    "            # update b_j = b_j + gamma * (df_dbj - dR_dbj)\n",
    "            V[-1, adv_index(item_list, sorted(J))] += gamma * (df_dbj - dR_dbj)\n",
    "\n",
    "        if len(K) != 0:\n",
    "            # NABULA V_k\n",
    "            df_dbk = - sigmoid(- r_hat_uJK) / len(K)\n",
    "            dR_dbk = 2 * lambda_b * b_K / len(K)\n",
    "            df_dVk = df_dbk * U_u\n",
    "            dR_dVk = 2 * lambda_v * V_bar_K / len(K)\n",
    "            # update V_k = V_k + gamma * (df_dVk - dR_dVk)\n",
    "            V[:-1, adv_index(item_list, sorted(K))] += gamma * (df_dVk - dR_dVk)[:,None] # trick: transpose here\n",
    "            # update b_k = b_k + gamma * (df_dbk - dR_dbk)\n",
    "            V[-1, adv_index(item_list, sorted(K))] += gamma * (df_dbk - dR_dbk)\n",
    "\n",
    "        # update estimation\n",
    "        estimation = np.dot(U, V)\n",
    "        # Postfix will be displayed on the right,\n",
    "        # formatted automatically based on argument's datatype\n",
    "        t.set_postfix(loss=bprh_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}